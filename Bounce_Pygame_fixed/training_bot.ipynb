{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import pygame as pg\n",
    "import numpy as np\n",
    "from main import Game\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from datetime import datetime\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class MyGameEnv(gym.Env):\n",
    "    def __init__(self, render_mode=True, log_mode=False, bug_mode=False, control_mode=\"bot\", train_mode=False):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self.log_mode = log_mode\n",
    "        self.bug_mode = bug_mode\n",
    "        self.control_mode = control_mode\n",
    "        self.train_mode = train_mode\n",
    "        self.model = None\n",
    "        self.game = None\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0.0, 0.0, -1.0, -1.0, 0.0], dtype=np.float32),\n",
    "            high=np.array([1.0, 1.0, 1.0, 1.0, 1.0], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    def game_setting(self):\n",
    "        self.game = Game(model= self.model, render_mode = self.render_mode, log_mode=self.log_mode, bug_mode=self.bug_mode, control_mode=self.control_mode, train_mode=self.train_mode)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs = self.game.reset()\n",
    "        return np.array(obs, dtype=np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "\n",
    "        if done: # step마다 reward 기록용\n",
    "            print(f\"[EP DONE] obs: {obs}, reward: {reward}\")\n",
    "        return np.array(obs, dtype=np.float32), reward, done, False, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode:\n",
    "            self.game.draw()\n",
    "\n",
    "    def close(self):\n",
    "        self.game.quitgame()\n",
    "\n",
    "    def train(self):\n",
    "        self.render_mode = False\n",
    "        self.log_mode = False\n",
    "        self.bug_mode = False\n",
    "        self.control_mode = \"bot\"\n",
    "        self.train_mode = True\n",
    "        self.game_setting()\n",
    "\n",
    "        # check_env(env, warn=True)  # 환경이 gym 스타일로 잘 되어 있는지 체크\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_name = f\"dqn_model_{timestamp}\"\n",
    "        model_name = os.path.join(\"./bot\", model_name)\n",
    "\n",
    "        model = DQN(\"MlpPolicy\", self, verbose=1, tensorboard_log=\"./dqn_logs\")\n",
    "        model.learn(total_timesteps=50000, tb_log_name=\"run_1\")\n",
    "        os.makedirs(\"./bot\", exist_ok=True)\n",
    "\n",
    "        model.save(model_name)\n",
    "        self.model = model\n",
    "        # self.close()\n",
    "\n",
    "    def check_env(self):\n",
    "        check_env(self)\n",
    "        # self.close()\n",
    "        \n",
    "    def load_model(self, model_name):\n",
    "        self.model = DQN.load(os.path.join(\"./bot\", model_name))\n",
    "        \n",
    "    def play_game_with_bot(self):\n",
    "        assert self.control_mode == \"bot\"\n",
    "        assert self.model is not None\n",
    "        assert self.train_mode == False\n",
    "        self.game_setting()\n",
    "        self.game.show_start_screen()\n",
    "        while self.game.running:\n",
    "            self.game.new()\n",
    "            self.game.show_go_screen()\n",
    "        self.game.quitgame()\n",
    "\n",
    "    def playNbug_detect(self):\n",
    "        assert self.control_mode == \"bot\"\n",
    "        assert self.model is not None\n",
    "        assert self.train_mode == False\n",
    "        self.game_setting()\n",
    "        while self.game.running:\n",
    "            self.game.new()\n",
    "        self.game.quitgame()\n",
    "\n",
    "        self.logging_name = self.game.logging_name\n",
    "        log_dir = \"log\"\n",
    "        gpt_dir = \"bug_detect\"\n",
    "        os.makedirs(gpt_dir, exist_ok=True)\n",
    "\n",
    "        load_dotenv()\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        with open(os.path.join(log_dir, self.logging_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            log_text = f.read()[-20000:] #로그 길이 제한\n",
    "        client = OpenAI()\n",
    "        response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"너는 게임 QA 테스터야. 내가 너에게 제공하는 게임 로그가 담긴 텍스트를 확인하고, 1번. 어느 곳에서 어떠한 '버그'가 나타났는지 파악해야 해. 2. 그 때의 상황을 자세히 설명해야 해. 3. 왜 그것이 버그인지 이유를 정리해서 말해야 해. 4. 무엇을 고쳐야 하는지에 대한 해결책도 정리해서 말해야 해.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"이건 게임 로그가 담긴 텍스트야.\n",
    "\n",
    "            --- LOG START ---\n",
    "            {log_text}\n",
    "            --- LOG END ---\n",
    "            \"\"\"\n",
    "            }\n",
    "            ]\n",
    "            )\n",
    "\n",
    "        summary = response.output_text\n",
    "\n",
    "        with open(os.path.join(gpt_dir, self.logging_name), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env 설정 제대로 되었는지 확인.\n",
    "env = MyGameEnv()\n",
    "check_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 훈련\n",
    "env = MyGameEnv()\n",
    "env.train()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공이 안움직이는 것 같다... 문제를 해결해보자. 05/22/12:06. //\n",
    "step이 길어질수록 reward를 작게 하자. 벽에 걸려서 아예 움직이지 못하는 이슈가 있네요.\n",
    "\n",
    "05/25/16:41 봇은 대충 만들었어요. show_go_screen 화면이 나오지 않는 현상을 해결해야 합니다.\n",
    "\n",
    "05/27/22:37 모두 완성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 로드 및 실제 플레이 화면 도출. 또한 로그 파일 저장 후에 바로 GPT에 물어봐서 버그를 파악하도록 함.\n",
    "env = MyGameEnv(render_mode=True, log_mode=True, bug_mode=True, control_mode=\"bot\", train_mode=False)\n",
    "env.load_model(model_name = \"dqn_model_20250525_140415.zip\")\n",
    "env.playNbug_detect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bug_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
